# Master's Thesis: "Enhancing the Robustness of Deep Neural Networks Using Radial Basis Functions"
### Author: Matthew P. Burruss
### Date: May 8th 2020

Enhancing the robustness of deep neural networks using radial basis functions (RBFs). The [paper can be found here](https://www.linkedin.com/posts/matthew-burruss-6034a2126_masters-thesis-activity-6646062841801555968-RWdl) and a video of the thesis defense can be found [here](https://drive.google.com/drive/folders/10Ek4SH2mBVL-M8pUb7pH-dT_qGDcblDs).

# Security Threat 1: Black-Box Physical Attack
## Replicating the physical attack RBF detection mechanism performed on DeepNNCar
Please see ```DeepNNCar.ipynb``` file and follow the ReadMe section.

For videos of DeepNNCar using the RBF to detect the physical attack in real-time, videos can be found [here](https://drive.google.com/drive/folders/10Ek4SH2mBVL-M8pUb7pH-dT_qGDcblDs).


# Security Threat 2: Poisoning Attack
## Replicating the data poisoning attacks and the RBF outlier detection method to clean poisoned data sets.
Please see the ```DataPoisoning.ipynb``` file and follow the ReadMe section.

# Security Threat 3: White-Box Adversarial Attack
## Replicating adversarial attack on the InceptionV3 architecture using a portion of the ILSRVC2012 data set
Please see the ```AdversarialAttack.ipynb``` file and follow the ReadMe section.
